{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python beginners course - Level 4 - Scikit-learn (machine learning)\n",
    "One of the reasons Python has become so popular in the last decade is its rich ecosystem of libraries that can be used for various applications. Currently one of the biggest applications of Python is in the field of `machine learning`. The fact that Python has become the de facto programming language in this area can be largely attributed to the package `scikit-learn`, a machine learning package which makes it increadibly convenient to:\n",
    "- prepare your data such that it can be used for machine learning\n",
    "- create and train a machine learning model\n",
    "- evaluate the performance of your model\n",
    "- use your model to make predictions\n",
    "\n",
    "This notebook will go through the functionality of `scikit-learn` and demonstrate the power of the package in the area of machine learning.\n",
    "\n",
    "\n",
    "## 1. What is machine learning?\n",
    "To illustrate what machine learning is, assume you have the following sequence of numbers\n",
    "- 3 - 9\n",
    "- 4 - 16\n",
    "- 5 - 25\n",
    "- 9 - **X**\n",
    "\n",
    "What number should be at **X**? Quite easy right? \n",
    "\n",
    "This exercise is easy for humans, because our brains are capable of `learning from experience`, we learn the pattern from the given data and we are able to apply this to new data. However, this exercise is not so easy for computers as they do not inherently have this creative capability, we have to give computers a framework to learn. This is exactly what `machine learning` is, it is providing the computer with a structured framework with which the computer is able to learn from experience.\n",
    "\n",
    "These frameworks are often referred to as algorithms and models, which the computer uses to perform a specific task without using explicit instructions. For example, if we would try to teach a computer to learn what **X** should be, we wouldn't give it any instructions apart from:\n",
    "\n",
    "    \"Given the sequence (3,9), (4,16), (5,25), (9,X), find out the value of X.\"\n",
    "\n",
    "It is then up to the model to find the relation in the given sequence.\n",
    "\n",
    "In machine learning, quite a lot of terminilogy is used. Here we will explain the most important terms:\n",
    "- **Target**: this is the value you are trying to predict. In our example, we are trying to predict the second number, given the first number. Therefore, the numbers 9, 16, 25, X are our targets.\n",
    "\n",
    "\n",
    "- **Feature(s)**: The input numbers 3,4,5,9 are what we call features, we use them to predict the target. In our example we only have 1 feature, but in almost all real-life problems you have many more features.\n",
    "\n",
    "\n",
    "- **Training data**: In our example, we used the three first sets of numbers to learn the pattern. These sets are what we refer to as training data; we use this data to train our model; to learn the relationship between the features and the target.\n",
    "\n",
    "\n",
    "- **Test data**: Once we have trained our model, we want to assess how well our model was able to learn the patterns in the data. Therefore, we use a set of data on which we test our model; the test data. \n",
    "\n",
    "\n",
    "- **Prediction**: When training a model, you both have features and a target. For example in our case, we both have the feature 5 and the target 25. However, after training we want to use our model to determine the target given any features. In other words, we want to give the model a feature, and it should return us the target based on the relationship that is has learned from the training data.\n",
    "\n",
    "\n",
    "- **Evaluation**: Given a trained model, you want to be able to assess how well the model has learned the patterns/relationships in the data. For this we evaluate our model on the test data. In our example, the numbers (9,81), (10,100) could be a test set. We would then use our model to predict the target given the feature 9 (and 10) and compare it to the actual value 81 (and 100). Calculating the difference between our predicted value and the actual value gives a measure for how well the model performs.\n",
    "\n",
    "These terms will be frequently used such that the reader can get familiarized with them as much as possible.\n",
    "\n",
    "The example given above is a relatively easy problem. However, the applications of machine learning extend to almost any area. Some real-life applications where machine learning is currently being used are\n",
    "\n",
    "- Self-driving car software\n",
    "- Analyzing MRI brain scans to detect tumours\n",
    "- E-mail filtering for spam\n",
    "- Fraud detection\n",
    "- Forecasting (product demands, weather, exchange rates, stock prices, ...)\n",
    "- Virtual assistants (chat bot, voice bot, ...)\n",
    "- Online recommendations (Netflix movies, Facebook friends, Amazon products, ...)\n",
    "- Sentiment analysis in written text\n",
    "- News classification\n",
    "- Speech recognition\n",
    "\n",
    "\n",
    "In this notebook, we will again be using the `Boston dataset` which we have used in the previous notebooks. We will use some of the features (columns) of the data to predict the house price (target). As features we will be using:\n",
    "\n",
    "| Feature        | Represents                                      |\n",
    "| :------------- |------------------------------------------------ | \n",
    "| RM | average number of rooms per dwelling|\n",
    "| LSTAT | percentage lower status of the population|\n",
    "\n",
    "and our target will be\n",
    "\n",
    "| Target        | Represents                                      |\n",
    "| :------------- |------------------------------------------------ | \n",
    "| MEDV | Median value of owner-occupied homes (1 = 1000 dollar)|\n",
    "\n",
    "In order to predict our target, we will take the following steps\n",
    "\n",
    "2. Prepare the data\n",
    "3. Choose the model(s)\n",
    "4. Train the model(s)\n",
    "5. Prediction and evaluation the model(s)\n",
    "6. (Optional) Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the packages that we will be using\n",
    "import numpy as np    # NumPy\n",
    "import pandas as pd   # Pandas\n",
    "import sklearn        # Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparing the data\n",
    "\n",
    "In any real-life application, the data is almost always far from perfect. There exist missing values, the data is in an improper format or there are inconsistencies between files. Therefore, before we can use the data for machine learning, there needs to be done some preparation on the data.\n",
    "\n",
    "Data preparation is the process of transforming raw data so that data scientists and analysts can run it through machine learning algorithms to uncover insights or make predictions. During data preparation, you tackle the mentioned problems:\n",
    "\n",
    "1. **Missing or incomplete records.** It is difficult to get every data point for every record in a dataset. Missing data sometimes appear as empty cells or a particular character, such as a question mark.\n",
    "\n",
    "\n",
    "2. **Improperly formatted data.** Data sometimes needs to be extracted into a different format or location. A good way to address this is to consult domain experts or join data from other sources.\n",
    "\n",
    "\n",
    "3. **The need for techniques such as feature engineering.** Even if all of the relevant data is available, the data preparation process may require techniques such as feature engineering to generate additional content that will result in more accurate, relevant models. For example, you might want to extract the 'month of year', 'week of month' or 'day of month' from a date.\n",
    "\n",
    "\n",
    "4. **Splitting the data.** In order to assess the performance of a model, we need to have a dataset. Therefore, the dataset needs to be split into a training and test set. The model will be trained on the training set, and then the performance will be assessed on the test set.\n",
    "\n",
    "In the `Boston dataset`, the first three steps have already been performed. Thus we only need to split our data into a training and test set.\n",
    "\n",
    "Before we start splitting our data, we must first load our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our data\n",
    "data = pd.read_csv('../data/boston_dataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our data, we see that we have a lot more columns than the ones we will be using (RM, LSTAT and MEDV). We will begin by throwing away all the data that we do not need.\n",
    "\n",
    "### Exercise: select only the RM, LSTAT and MEDV columns from the data\n",
    "Replace the ```___``` in the following cell to complete the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the columns RM, LSTAT and MEDV from data\n",
    "data = data[[___]]\n",
    "\n",
    "# Print the obtained Dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have removed all the features that we will not be using, we will split the data into a training set on which the models will be trained, and a test set on which the model's performance will be assessed. Remember from the `Pandas` notebook that we can select rows from a Dataframe using `.iloc`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the first 5 rows of data\n",
    "first_5_rows = data.iloc[0:5]\n",
    "\n",
    "# Print the first 5 rows to the screen\n",
    "first_5_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to split our data such that approximately 80% of the rows is in the training set and the remaining 20% is the test set. To create such distribution, we first need to know how many rows our data has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of columns\n",
    "print('The data has {} columns'.format(data.shape[1]))\n",
    "\n",
    "# Print the number of rows\n",
    "print('The data has {} rows'.format(data.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has 506 rows. This means that we want 404 rows (80% of 506) in our training data set, and 102 rows in our test data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Split the data into two parts:\n",
    "1. A training data set with the first 404 rows of the data\n",
    "2. A test data set with the remaining 102 rows of the data\n",
    "\n",
    "Replace the ```___``` in the following cell to complete the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data.iloc[___]\n",
    "data_test  = data.iloc[___]\n",
    "    \n",
    "print('The training data set has {} rows'.format(data_train.shape[0]))\n",
    "print('The test data set has {} rows'.format(data_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training and test data sets contain both the features (RM, LSTAT) and the target (MEDV) that we are trying to predict. We also want to split our features from the target.\n",
    "\n",
    "We can do this very easily with the datasets we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is almost always used to denote the variable containing the features\n",
    "X_train = data_train[['LSTAT', 'RM']]\n",
    "\n",
    "# y is almost always used to denote the variable containing the target\n",
    "y_train = data_train['MEDV']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell splits the features from the target for the training data, let's do the same for the test data.\n",
    "\n",
    "### Exercise: split the test data set into features and target.\n",
    "Replace the ```___``` in the following cell to complete the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = ___\n",
    "y_test = ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now manually split the data in a training set and a test set, and split the target from the features. However, we as programmers are lazy and do not want to do this manually... So let's use a library that can do this for us! (but does exactly the same as we just did!)\n",
    "\n",
    "If you did not already guess so, `scikit-learn` can do this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function that can do the splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Perform the splitting between training/test and features/target\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[['LSTAT', 'RM']], data['MEDV'], test_size=0.20, random_state=42)\n",
    "\n",
    "# Print the results\n",
    "print('The training data set has {} rows'.format(X_train.shape[0]))\n",
    "print('The test data set has {} rows'.format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Choosing the model(s)\n",
    "In our dataset, we have a set of features (RM, LSTAT) and we are trying to predict the house price (our target, MEDV). This is a classic example of a regression problem, where we are trying to find the relation between features and a target. \n",
    "\n",
    "To illustrate regression, imagine we only have 1 feature and our target. Visualizing our data, it could look something like the blue dots in the figure below. The challenge would then be to find a function (red line) that fits our data best, which in this case is a linear line (Linear Regression).\n",
    "\n",
    "<img src=\"../assets/linear-regression.png\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "Choosing the model that does this best for an arbitrary dataset is not trivial. Usually, many different types of models are trained. Each of them is then evaluated on the test data set, to check how 'good' they fit the data and the one with the best performance is used. However, since the process of training and checking the performance is often very costly, data scientists try to find information in the dataset that hints at using a specific type of model.\n",
    "\n",
    "For example, if you have made some visualizations of the data and figured out that there is a strong linear correlation between the features and the target, you would not want to use a non-linear model. An example of those visualizations is given below, from which a linear relation between the features and target becomes obvious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib to plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a subplot object\n",
    "plt.subplots(figsize=[12,6])\n",
    "\n",
    "# Visualize relation between the feature RM and the target MEDV\n",
    "plt.subplot(121)\n",
    "plt.scatter(data['RM'], data['MEDV'])\n",
    "plt.title('Relation between RM and MEDV')\n",
    "plt.xlabel('RM')\n",
    "plt.ylabel('MEDV')\n",
    "\n",
    "# Visualize relation between the feature LSTAT and the target MEDV\n",
    "plt.subplot(122)\n",
    "plt.scatter(data['LSTAT'], data['MEDV'])\n",
    "plt.title('Relation between LSTAT and MEDV')\n",
    "plt.xlabel('LSTAT')\n",
    "plt.ylabel('MEDV')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From both scatter plots we can see that there seems to be a linear relationship between the features and our target. Therefore, we will try a linear regression model. Furthermore, we will also use a Random forest model (multiple decision trees) to illustrate how to compare the performance of different models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training the model(s)\n",
    "For our problem, we will be training two different types of models:\n",
    "- Linear regression model\n",
    "- Random forest model (used for example in the Quick-Pay algorithm)\n",
    "\n",
    "The market standard library for making these models in Python is `scikit-learn`. The main reason for this is (as we will see) that it is **very** easy to make and train machine learning models using this library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model we want to use from scikit-learn: a linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create an estimator (not officially a model yet, since we haven't trained it yet)\n",
    "linear_regression_estimator = LinearRegression()\n",
    "\n",
    "# Learn the relationship between the features and the target using the .fit() method\n",
    "linear_regression_model = linear_regression_estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! We now have a linear regression model with which we can predict our target.\n",
    "\n",
    "Let's do the same, but now for a Random Forest model.\n",
    "\n",
    "### Exercise:\n",
    "1. Create a Random Forrest estimator\n",
    "2. Fit the estimator to create the model\n",
    "\n",
    "Replace the ```___``` in the following cell to complete the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model we want to use from scikit-learn: a random forest model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create an estimator\n",
    "random_forrest_estimator = ___\n",
    "\n",
    "# Fit the estimator to create a model\n",
    "random_forrest_model = ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Prediction and evaluation the model(s)\n",
    "We now have two trained models, a linear regression model and a Random forest model. Each of them has learned a relationship between the features and our target. However, we do not know how succesfull they were in actually learning the correct relationship; we want to measure the performance of the model and use the model with the best performance to do our predictions.\n",
    "\n",
    "To measure how 'well' a model fit the data, we need to introduce some metrics than quantify the error. The metrics we will try out are:\n",
    "- Mean Absolute Error (MAE)\n",
    "- Mean Squared  Error (MSE)\n",
    "\n",
    "To illustrate these concepts consider again the situation where we have only 1 feature and a target, and assume we have created a linear regression model to that data as shown in the figure below. We then can calculate our metrics as follows:\n",
    "- MAE: calculate the distance from each target to our models approximation (red line), add all of these distances, and divide by the number of points we have (in this case 7). [More info](https://en.wikipedia.org/wiki/Mean_absolute_error).\n",
    "\n",
    "\n",
    "- MSE: calculate the distance from each target to our models approximations (red line), square these values and add all of them, and divide by the number of points we have (in this case 7). [More info](https://en.wikipedia.org/wiki/Mean_squared_error).\n",
    "\n",
    "<img src=\"../assets/MSE.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "Many more metrics exist. The choice often depends on the type of problem that is being solved. For example, if you do not want to have large errors, the MSE metric is preferred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Why is the MSE metric preferred for problems where large errors are undesirable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now calculate the MAE and MSE metrics for the linear regression model. In the code below, we first import both the functions from `scikit-learn` which do this for us; `mean_absolute_error` and `mean_squared_error` respectively.\n",
    "\n",
    "Then, the predictions of the target `MEDV` are calculated on the test set that we defined. Using the real targets and the predicted targets, the metrics can then be calculated and printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the metrics that we want to use\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Calculate our predictions for the linear regression model on the test data\n",
    "linear_regression_predictions = linear_regression_model.predict(X_test)\n",
    "\n",
    "# Calculate the metrics for the linear regression predictions\n",
    "linear_regression_MAE = mean_absolute_error(y_test, linear_regression_predictions)\n",
    "linear_regression_MSE = mean_squared_error(y_test, linear_regression_predictions)\n",
    "\n",
    "# Print the values of the metrics\n",
    "print('The MAE for the linear regression model = ', linear_regression_MAE)\n",
    "print('The MSE for the linear regression model = ', linear_regression_MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: \n",
    "1. Calculate the predictions for the Random Forrest model\n",
    "2. Calculate the metrics for the Random Forrest predictions\n",
    "\n",
    "Replace the ```___``` in the following cell to complete the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate our predictions for the Random Forrest model\n",
    "random_forrest_predictions = random_forrest_model.___\n",
    "\n",
    "# Calculate the metrics for the linear regression predictions\n",
    "random_forrest_MAE = ___\n",
    "random_forrest_MSE = ___\n",
    "\n",
    "# Print the values of the metrics\n",
    "print('The MAE for the linear regression model = ', ___)\n",
    "print('The MSE for the linear regression model = ', ___)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Which of the two models performs best? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ofcouse, for mathematicians it is nice to see the performance of a model expressed as a number. However, it is much more intuitive to visualize the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Adjust the code below such that the Random forest predictions are also shown\n",
    "\n",
    "Replace the ```___``` in the following cell to complete the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figure size\n",
    "fig, ax = plt.subplots(figsize=[16,6])\n",
    "\n",
    "# Plot the original data\n",
    "plt.plot(y_test.values, 'k', label='Original data')\n",
    "\n",
    "# Plot the linear regression predictions\n",
    "plt.plot(linear_regression_predictions, label='Linear Regression')\n",
    "\n",
    "# Plot the random forrest predictions\n",
    "# plt.plot(___)\n",
    "\n",
    "# Show a legend in the plot\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
