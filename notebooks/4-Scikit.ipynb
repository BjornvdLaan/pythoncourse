{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python beginners course - Level 2 - Scikit (Machine Learning)\n",
    "Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to perform a specific task without using explicit instructions, relying on patterns and inference instead. It is seen as a subset of artificial intelligence. Machine learning algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to perform the task. Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or infeasible to develop a conventional algorithm for effectively performing the task.\n",
    "\n",
    "In machine learning, we have a set of features and a target and we are aiming at finding the relationship between the features and the target. In our example, the features are the properties of the house (number of rooms/size/...) and some demographic information (neighborhood information), and our target is the house price. We are thus trying to figure out what the relation is between the properties of the house, and the price.\n",
    "\n",
    "Generally, machine learning consists of the following steps\n",
    "1. Gathering data\n",
    "2. Preparing that data (imputing missing values/aggregating/feature extraction/test-train split)\n",
    "3. Choosing a model\n",
    "4. Training (fit your model on the training data)\n",
    "5. Evaluation (see how well the model fits the test data)\n",
    "6. Hyperparameter tuning\n",
    "7. Prediction (predict on new data)\n",
    "\n",
    "Each (except 1, 6, 7) of these steps will be elaborated on in more detail below. \n",
    "\n",
    "\n",
    "[Source](https://en.wikipedia.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/boston_dataset.csv')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preparing the data\n",
    "\n",
    "Data preparation is the process of transforming raw data so that data scientists and analysts can run it through machine learning algorithms to uncover insights or make predictions.\n",
    "\n",
    "The data preparation process can be complicated by issues such as:\n",
    "\n",
    "1. **Missing or incomplete records.** It is difficult to get every data point for every record in a dataset. Missing data sometimes appear as empty cells or a particular character, such as a question mark. \n",
    "2. **Improperly formatted data.** Data sometimes needs to be extracted into a different format or location. A good way to address this is to consult domain experts or join data from other sources.\n",
    "3. **The need for techniques such as feature engineering.** Even if all of the relevant data is available, the data preparation process may require techniques such as feature engineering to generate additional content that will result in more accurate, relevant models. For example, you might want to extract the 'month of year', 'week of month' or 'day of month' from a date.\n",
    "4. **Splitting the data.** In order to assess the performance of a model, we need to have a dataset. Therefore, the dataset needs to be split into a training and test set. The model will be trained on the training set, and then the performance will be assessed on the test set.\n",
    "\n",
    "In our dataset, the first three steps have already been performed. It thus only remains for us to do the train-test split.\n",
    "\n",
    "Remember from earlier that we can do slicing on our dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_5_rows = data[0:5]\n",
    "first_5_rows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** \n",
    "1. Split the data (506 rows) into two parts: `data_train` and `data_test`. `data_train` contains the first 400 rows, and `data_test` the remaining 106 rows. \n",
    "2. Print the size of each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data.iloc[___]\n",
    "data_test  = data.iloc[___]\n",
    "    \n",
    "print('The size of data_train = ', data_train.___)\n",
    "print('The size of data_test  = ', data_test.___)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we split the rows, we also want to split the features from the target that we are trying to predict. We can do this very easily with the datasets we just created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train[['LSTAT', 'RM']]\n",
    "y_train = data_train['MEDV']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:**\n",
    "1. Do the same, but now for the test set (split features and target)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_... = data_...[[...]]\n",
    "y_... = data_...[...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now manually split the data in a training set and a test set, and split the target from the features. However, we as programmers are lazy and do not want to do this manually... So let's use a library that can do this for us! (but does exactly the same as we just did!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[['LSTAT', 'RM']], data['MEDV'], test_size=0.20, random_state=42)\n",
    "\n",
    "print(f'The training set contains {X_train.shape[0]} samples')\n",
    "print(f'The training set contains {X_test.shape[0]} samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Choosing a model\n",
    "In our dataset, we have a set of features and we are trying to predict the house price (our target). This is a classic example of a regression problem, where we are trying to find the relation between features and a target. \n",
    "\n",
    "To illustrate regression, imagine we only have 1 feature and our target. Visualizing our data, it could look something like the blue dots in the figure below. The challenge would then be to find a function (red line) that fits our data best, which in this case is a linear line (Linear Regression).\n",
    "\n",
    "<img src=\"../assets/linear-regression.png\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "Choosing the model that does this best is not trivial. Usually, many different types of models are trained. For each of them, it is then checked how 'good' they fit the data and the one with the best performance is used. However, since the process of training and checking the performance is often very costly, data scientists try to find information in the dataset that hints at using a specific type of model.\n",
    "\n",
    "### 4. Training\n",
    "For our problem, we will be training two different types of models:\n",
    "- Linear regression model\n",
    "- Random forest model (used for example in the Quick-Pay algorithm)\n",
    "\n",
    "The market standard library for making these models in Python is `sklearn`. The main reason for this is (as we will see) that it is **very** easy to make and train machine learning models using this library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model we want to use from sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create an estimator (not officially a model yet, since we haven't trained it yet)\n",
    "linear_regression_estimator = LinearRegression()\n",
    "\n",
    "# Fit the estimator, now we have a model!\n",
    "linear_regression_model = linear_regression_estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! We now have a linear regression model with which we can predict our target.\n",
    "\n",
    "Let's do the same, but now for a Random Forest model.\n",
    "\n",
    "**Exercise:**\n",
    "1. Create a Random Forrest estimator\n",
    "2. Fit the estimator to create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Random Forrest model from sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create an estimator\n",
    "random_forrest_estimator = ___\n",
    "\n",
    "# Fit the estimator to create a model\n",
    "random_forrest_model = ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluation\n",
    "Now that we have our trained machine learning models, we want to know which one of them has the best performance. In order to be able to assess the performance of a model, we need to define how we are going to measure performance. The metrics we will try out are:\n",
    "- Mean Absolute Error (MAE)\n",
    "- Mean Squared  Error (MSE)\n",
    "\n",
    "Let's imagine again that we have 1 feature and our target, and that we have fit a linear regression model to our data, as shown in the figure below. We then can calculate our metrics as follows:\n",
    "- MAE: calculate the distance from each point to our model (red line), add all of these distances, and divide by the number of points we have (in this case 7). [More info](https://en.wikipedia.org/wiki/Mean_absolute_error).\n",
    "- MSE: calculate the distance from each point to our model (red line), square these values and add all of them, and divide by the number of points we have (in this case 7). [More info](https://en.wikipedia.org/wiki/Mean_squared_error).\n",
    "\n",
    "<img src=\"../assets/MSE.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "Many more metrics exist. The choice often depends on the type of problem that is being solved. For example, if you do not want to have large errors, the MSE metric is preferred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge:** Why is the MSE metric preferred for problems where large errors are not wanted?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now calculate the MAE and MSE metrics for the linear regression model. In the code below, we first import both the functions which do this for us; `mean_absolute_error` and `mean_squared_error` respectively.\n",
    "\n",
    "Then, the predictions of the target `MEDV` are calculated on the test set that we defined. Using the real values and the predicted values, the metrics can then be calculated and printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the metrics that we want to use\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Calculate our predictions for the linear regression model\n",
    "linear_regression_predictions = linear_regression_model.predict(X_test)\n",
    "\n",
    "# Calculate the metrics for the linear regression predictions\n",
    "linear_regression_MAE = mean_absolute_error(y_test, linear_regression_predictions)\n",
    "linear_regression_MSE = mean_squared_error(y_test, linear_regression_predictions)\n",
    "\n",
    "# Print the values of the metrics\n",
    "print('The MAE for the linear regression model = ', linear_regression_MAE)\n",
    "print('The MSE for the linear regression model = ', linear_regression_MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** \n",
    "1. Calculate the predictions for the Random Forrest model\n",
    "2. Calculate the metrics for the Random Forrest predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate our predictions for the Random Forrest model\n",
    "random_forrest_predictions = random_forrest_model.___\n",
    "\n",
    "# Calculate the metrics for the linear regression predictions\n",
    "random_forrest_MAE = ___\n",
    "random_forrest_MSE = ___\n",
    "\n",
    "# Print the values of the metrics\n",
    "print('The MAE for the linear regression model = ', ___)\n",
    "print('The MSE for the linear regression model = ', ___)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Which of the two models performs best? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ofcouse, for mathematicians it is nice to see the performance of a model expressed as a number. However, it is much more intuitive to visualize the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Add the Random Forrest predictions to the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figure size\n",
    "fig, ax = plt.subplots(figsize=[16,6])\n",
    "\n",
    "# Plot the original data\n",
    "plt.plot(y_test.values, 'k', label='Original data')\n",
    "\n",
    "# Plot the linear regression predictions\n",
    "plt.plot(linear_regression_predictions, label='Linear Regression')\n",
    "\n",
    "# Plot the random forrest predictions\n",
    "plt.plot(___)\n",
    "\n",
    "# Show a legend in the plot\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Hyperparameter tuning\n",
    "\n",
    "In this course, we trained a Linear regression and Random Forrest model. All machine learning models have a lot of settings (called hyperparameters) that can be changed, in order to improve the performance. Since this is a quite advanced topic, we chose not to include this topic in the course. However, there is plenty of documentation online that nicely describe the concept of hyperparameter tuning. The interested reader is referred to external sources such as:\n",
    "\n",
    "[Hyperparameter explanation](https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)) <br>\n",
    "[Hyperparameter optimization](https://medium.com/criteo-labs/hyper-parameter-optimization-algorithms-2fe447525903)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge:** Change the hyperparameters of the Random Forrest model (and retrain the model) such that the performance of the MSE metric improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an estimator\n",
    "random_forrest_estimator = RandomForestRegressor(...)\n",
    "\n",
    "# Fit the estimator to create a model\n",
    "random_forrest_model = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Prediction\n",
    "\n",
    "Now that we have a trained model, we have a mapping between our features and the target (house price). Once a new house comes on the marget now, we do not need any external information to determine the price. We can simply determine the features (number of rooms/total area/...) and predict the price using our model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
